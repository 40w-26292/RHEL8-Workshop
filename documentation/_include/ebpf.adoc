:sectnums:
:sectnumlevels: 2
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

:toc:
:toclevels: 1

= BPF Tracing - Observability of System Performance

eBPF (The Extended Berkeley Packet Filter) is an in-kernel virtual machine that allows code execution in the kernel space, in a restricted sandbox environment with access to a limited set of functions. There are numerous components shipped by Red Hat that utilize the eBPF virtual machine. Each component is in a different development phase, and thus not all components are currently fully supported. Those that are not supported are avaialable as a *Technology Preview* and are not intended for production use.For information on Red Hat scope of support for Technology Preview features, see: link:https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Support Scope]

In this unit, we will be focusing on the kernel tracing offering shipped as bcc-tools (BPF Compiler Collection Tools). There are just over 100 tools shipped in this package. A few things of note:

     * All of these tools live in `/usr/share/bcc/tools`.
     * These tools must run as the root user as any eBPF program can read kernel data. As such, injecting eBPF bytecode as a regular user is not allowed in RHEL 8.
     * Each tool has a man page to view the man page, run `man <tool name>`. These man pages include descriptions of the tools, provide the options that can be called and have information on the expected overhead of the specific tool.

TIP: Now is a great time to use the multi session capability of *tmux*.  Using `Ctrl-b c` create another session.  You can now cycle back and forth between them with `CTRL-b n` (next) and `CTRL-b p` (previous).  Just make sure you are the user *root* on *workstation.example.com* in order to sucessfully run the rootkit script.

== Getting Started

There is a dedicated VM we will use for the container exercises.  From *workstation.example.com*, you should be able to ssh to *node2.example.com* as 'root' without any prompts for credentials.

.[root@workstation ~]#
----
ssh node2.example.com
----

Verify that you are on the right host for these exercises.

.[root@node2]#
----
cheat-ebpf-checkhost.sh
----

Now you are ready to begin your exercises with eBPF Tracing.

== Installation

Start by installing the *BPF Compiler Collection* bcc-tools package:

.[root@node2 ~]#
----
yum install bcc-tools -y
----

== Observing `yum update`

In this lab, we will be using some of the tools from the bcc-tools package to analyse what happens on a system during a `yum update`. We have picked `yum update` because it represents a non-trivial real world applicatio. In a `yum update`, we have the following activity happening:

     * TCP connections are established to configured repositories, which we will track with `gethostlatency` and `tcplife`.
     * Many files will be opened on our XFS filesystem, which we will observe with `filetop`. We will also use `xfsslower` to determine which XFS operations take longer than 10ms to execute.
     * Memory access. Linux uses a memory cache to ensure faster access to needed information than having to go to disk. Using cachestat, we will be able to see hits and misses on this cache in realtime. When everything Linux needs is chaced, we should have zero misses and while the cache is being populated, we will see a number of misses. If the cache continues to be populated beyond the size of the cache, Linux will employ a LRU (Least Recently Used) algorithm with a lot of heuristics and some cached data will be removed and replaced with new data.

To get started, let's run `bpftool` to verify that no eBPF programs are currently loaded in the kernel:

.[root@node2 ~]#
----
bpftool prog list
----

=== Setting up our observability terminals

Now that we've verified, that, let's open 5 new terminals and in each of those terminals, we will start a tool for observing the system. By doing this, we'll be able to move between the 5 terminals to observe what's happening while the yum update is running.

In the first new terminal, run:

.[root@node2 ~]#
----
/usr/share/bcc/tools/gethostlatency
----

`gethostlatency` is going to give us latency statistics on the getaddrinfo() and gethostbyname() system calls. Effectively, we'll get to see how long these take and which hostnames our applications need IP addresses for. This can be useful for discovering interseting connections that you may not be aware your applications are making.

In the second new terminal, run:

.[root@node2 ~]#
----
/usr/share/bcc/tools/tcplife
----

`tcplife` will give us a lot of data about established tcp connections, including the total time that the connections are alive. When yum is finished downloading packages, we should get entries in tcplife for the exact amount of time that yum spent downloading packages over the tcp connections that it established for this activity.

In the third new terminal, run:

.[root@node2 ~]#
----
/usr/share/bcc/tools/filetop
----

`filetop` will allow us to see which files are being accessed by which processes in realtime, so expect this terminal to be pretty busy while running `yum update`.

In the fourth new terminal, run:

.[root@node2 ~]#
----
/usr/share/bcc/tools/xfsslower
----

`xfsslower` will show us operations on XFS that take longer than 10ms. This terminal will likely stay pretty quiet until `yum update` starts installing the packages. Once it starts to install the packages, yum will push the boundaries of what our virtual machine's storage can keep up with while delivering <10ms latency on XFS operations. You will see operations taking longer than 10ms and the files these operations were operating on.

Finally, in the fifth new terminal, run:

.[root@node2 ~]#
----
/usr/share/bcc/tools/cachestat
----

`cachestat` enables us to see in real time the hits and misses on the Linux memory cache. The second column of output is misses and the third column is hits. We should have mostly 0 misses for the first part of the yum update. Once we get to the installation of packages, we should see our misses start to increase.

=== Observing the `yum update`

`yum update` goes through the following steps:

     * Updating repository metadata
     * Determining what packages on the system need to be updated
     * Downloading the appropriate packages for updates.
     * Installing the updates and removing old packages.
     * Verifying the updates have been successful.

Let's get started in our original terminal by running:

.[root@node2 ~]#
----
yum update -y
----

Now we can cycle through the various terminals and observe how the system is utilizing its available resources while doing a yum update.

[discrete]
== Additional Resources


NOTE: You are not required to reference any additional resources for these exercises.  This is informational only.

    * link:https://www.redhat.com/en/blog/bcc-tools-brings-dynamic-kernel-tracing-red-hat-enterprise-linux-81[bcc-tools brings dynamic kernel tracing to Red Hat Enterprise Linux 8.1]
    * link:https://www.redhat.com/en/blog/why-networkmanager-talking-staticredhatcom-find-out-bcc-tools[Why is NetworkManager talking to static.redhat.com? Find out with bcc-tools!]
    * link:https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_monitoring_and_updating_the_kernel/analyzing-system-performance-with-bpf-compiler_collection_managing-monitoring-and-updating-the-kernel[Analyzing System Performance with BPF Compiler Collection]
    * link:http://www.brendangregg.com/ebpf.html[Linux Extended BPF (eBPF Tracing Tools) - Brendan Gregg]

[discrete]
== End of Unit

link:../RHEL8-Workshop.adoc#toc[Return to TOC]

////
Alway end files with a blank line to avoid include problems.
////

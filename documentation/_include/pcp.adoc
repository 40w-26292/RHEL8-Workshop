:sectnums:
:sectnumlevels: 3
:markup-in-source: verbatim,attributes,quotes
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

:toc:
:toclevels: 1

= Performance Co-Pilot, Grafana, and bpftrace

== Overview

Performance Co-Pilot is a suite of tools, services, and libraries for monitoring, visualizing, storing, and analyzing system-level performance measurements. Starting with RHEL 8.2, we are delivering version 5.0.2, which has many enhancements, including providing link:https://openmetrics.io[OpenMetrics] compliant data over pmproxy that can be used by other collectors such as prometheus.

RHEL 8 also provides Grafana, a graphing, visualization tool, which we integrate with Performance Co-Pilot to graph metrics in real time.

Combined with bpftrace, we are able to get at very interesting data from the kernel.

== Getting Started

For these exercises, you will primarily be using the hosts `node2` and `node3`  as user `root`.  However, these exercises do REQUIRE a second terminal session to run commands on other hosts.  Please pay careful attention to what commands to run on different hosts.

TIP: Now is a great time to use the multi session capability of *tmux*.  Use `Ctrl-b "` to create another session with a split screen.  Cycle the active session back and forth with `CTRL-b n` (next) and `CTRL-b p` (previous).

From host `workstation`, ssh to `node2`.

[bash,options="nowrap",subs="{markup-in-source}"]
----
$ *ssh node2*
----

Use `sudo` to elevate your priviledges.

[bash,options="nowrap",subs="{markup-in-source}"]
----
$ *sudo -i*
----

Verify that you are on the right host for these exercises.

[bash,options="nowrap",subs="{markup-in-source}"]
----
# *cheat-pcp-checkhost.sh*
----

You are now ready to proceed with these exercises.

== Installation

Start by installing pcp,grafana,redis,js-d3-flame-graph, and others:

[bash,options="nowrap",subs="{markup-in-source}"]
----
# *yum install pcp grafana grafana-pcp cockpit-pcp bpftrace bcc-tools pcp-pmda-bpftrace cyrus-sasl-md5 cyrus-sasl-lib redis js-d3-flame-graph -y*
----

== pminfo and pmrep

Since we now have pcp installed and running on our machines, let's run the following on node1:

[bash,options="nowrap",subs="{markup-in-source}"]
----
pminfo | grep kernel | head -n 15
----

This will return similar output to:

[bash,options="nowrap",subs="{markup-in-source}"]
----
kernel.all.load
kernel.all.intr
kernel.all.pswitch
kernel.all.sysfork
kernel.all.running
kernel.all.blocked
kernel.all.boottime
kernel.all.hz
kernel.all.uptime
kernel.all.idletime
kernel.all.nusers
kernel.all.nroots
kernel.all.nsessions
kernel.all.lastpid
kernel.all.runnable
----

This represents 15 pcp metrics that have the word "kernel" in them. Let's use the `pmrep` command to see what the load on our system currently is:

[bash,options="nowrap",subs="{markup-in-source}"]
----
pmrep kernel.all.load -s 15
----

This will return output similar to:

[bash,options="nowrap",subs="{markup-in-source}"]
----
  k.a.load  k.a.load  k.a.load
  1 minute  5 minute  15 minut
                              
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
     0.010     0.010     0.000
----

This gives us 15 samples at a 1-second interval for the 1-minute, 5-minute, and 15-minute load average for this host. In order to make this more interesting, we can start stress-ng in the second terminal:

[bash,options="nowrap",subs="{markup-in-source}"]
----
stress-ng --aio 40 --cpu 20 &
----

and back in the first terminal:

[bash,options="nowrap",subs="{markup-in-source}"]
----
pmrep kernel.all.load -s 15
----

and our output will show more load this time:

[bash,options="nowrap",subs="{markup-in-source}"]
----
  k.a.load  k.a.load  k.a.load
  1 minute  5 minute  15 minut
                              
     1.600     0.330     0.110
     1.600     0.330     0.110
     1.600     0.330     0.110
     1.600     0.330     0.110
     3.080     0.660     0.210
     3.080     0.660     0.210
     3.080     0.660     0.210
     3.080     0.660     0.210
     3.080     0.660     0.210
     4.430     0.980     0.320
     4.430     0.980     0.320
     4.430     0.980     0.320
     4.430     0.980     0.320
     4.430     0.980     0.320
     5.680     1.300     0.430
----

Now in the second terminal, run:

[bash,options="nowrap",subs="{markup-in-source}"]
----
killall -9 stress-ng
----

This stops our stress-ng process and will allow the load on the system to return to normal.

Also, with pmrep, we can create ini files that allow us to build pcp reports. A pcp report to measure memory utilization would look like:

[bash,options="nowrap",subs="{markup-in-source}"]
----
[mem-util]
timestamp=yes
interval=1s
mem.util.bufmem=
mem.util.cached=
mem.util.free=
mem.util.used=
----

This is from the file `rhel-use.conf` and if we run this report, we will have timestamped data sampled at a 1 second interval that will include the pcp metrics: `mem.util.bufmem`, `mem.util.cached`, `mem.util.free`, `mem.util.used`. Let's use `pmrep` and rhel-use.conf to sample memory. But first, in our second terminal, let's generate some memory load:

[bash,options="nowrap",subs="{markup-in-source}"]
----
stress-ng --vm 20 &
----

and in the first terminal:

[bash,options="nowrap",subs="{markup-in-source}"]
----
pmrep -c rhel-use.conf :mem-util -s 15
----

This will print output similar to:

[bash,options="nowrap",subs="{markup-in-source}"]
----
          m.u.bufmem  m.u.cached  m.u.free  m.u.used
               Kbyte       Kbyte     Kbyte     Kbyte
20:58:49           0     1589892     89752   1770152
20:58:50           0     1502764    159928   1699976
20:58:51           0     1628788     52140   1807764
20:58:52           0     1587184     57004   1802900
20:58:53           0     1601804     76884   1783020
20:58:54           0     1610292     72720   1787184
20:58:55           0     1555400    120180   1739724
20:58:56           0     1002124    649464   1210440
20:58:57           0     1629744     52336   1807568
20:58:58           0     1621704     52664   1807240
20:58:59           0     1614144     75640   1784264
20:59:00           0     1612628     53104   1806800
20:59:01           0     1584568    105372   1754532
20:59:02           0     1602292     87688   1772216
20:59:03           0     1606756     67600   1792304
----

Now in our second terminal, let's run:

[bash,options="nowrap",subs="{markup-in-source}"]
----
killall -9 stress-ng
----

From this, we can see that pmrep is a powerful tool for reporting on pcp metrics at the command line.

== pmseries enablement

pmseries allows pcp to store data in a redis database. This allows for searching historical data at a later time, which can be quite useful during the post mortem of a performance event. 

To set up pmseries, on node2, please edit /etc/pcp/pmseries/pmseries.conf and make sure the following under `[pmproxy]` is set:

----
# support Redis protocol proxying
redis.enabled = true
----

Then make sure that under `[pmseries]`, you have the following set:

----
# allow REST API queries of fast, scalable time series
enabled = true
----

Once these are both set, save the file and run:

----
systemctl restart pmcd pmlogger pmproxy
----

It will take pmseries a few minutes to have data collected, but once this has began, you can run:

----
pmseries kernel.all.load
----

and get output similar to:

----
fc13f67815676cd1ed1687fe55030c9e8c33b059
----

which verifies that pmseries is storing data in redis. We will view this data in grafana.

== bpftrace pmda Initial Setup

Let's install the bpftrace pmda to examine how this works. The rpm is already installed on the system, but we still have to install the pmda into pcp. On node2, run:

----
cd /var/lib/pcp/pmdas/bpftrace
./Install
pmrep bpftrace.scripts.runqlat.data.usecs -s 5
----

This should return 5 samples of run queue latency measured in microseconds:

----
  b.s.r.data_bytes
            byte/s
               N/A
           570.033
           573.032
           572.621
           573.303
           573.271
           572.550
           573.998
           574.196
           575.521
           572.610
           574.096
           575.030
           577.681
           577.983
----

Now how did that happen? If we examine the `/var/lib/pcp/pmdas/bpftrace/autostart` directory, we will see two included bpftrace scripts:

----
ls -lah /var/lib/pcp/pmdas/bpftrace/autostart/
----

----
total 8.0K
drwxr-xr-x. 2 root root  45 Aug  6 20:10 .
drwxr-xr-x. 4 root root 161 Aug 13 21:24 ..
-rw-r--r--. 1 root root 601 Jun 23 05:21 biolatency.bt
-rw-r--r--. 1 root root 794 Jun 23 05:21 runqlat.bt
----

If we look at runqlat.bt, we will see a line in the code that reads:

----
                @usecs = hist((nsecs - $ns) / 1000);
----

This pmda has converted this `@usecs` bpfmap to a pcp metric. To see all pcp metrics from this script, run:

----
pminfo | grep bpftrace | grep runqlat
----

and you will see:

----
bpftrace.scripts.runqlat.data.usecs
bpftrace.scripts.runqlat.data_bytes
bpftrace.scripts.runqlat.code
bpftrace.scripts.runqlat.probes
bpftrace.scripts.runqlat.error
bpftrace.scripts.runqlat.exit_code
bpftrace.scripts.runqlat.pid
bpftrace.scripts.runqlat.status
----

As such, any bpftrace script placed in the "autostart" directory will be parsed, run, and made available through pcp in this manner. If you add a bpftrace script, you do need to run `Remove` followed by `Install` in the `/var/lib/pcp/pmdas/bpftrace/` directory for this script to be picked up. This makes for a powerful integration between pcp and bpftrace.

== Remote Logging Setup

Let's use our pcp node2 as a remote logging server and our pcp node3 as a client. To do this, let's go to node3 and set up pmlogger as a client:

Use `ip addr` to determine the ip address of your machine. For this example, we'll say the IP address is 192.168.1.4.

Edit /etc/pcp/pmcd/pmcd.options and set:
----
-i 192.168.1.4
----

Please replace `192.168.1.4` with your actual IP address.

Save this file and then we will need to open some services on the firewall:

----
firewall-cmd --add-service=pmproxy --add-service=pmcd --permanent
firewall-cmd --reload
----

Now we need to all pcp to bind to unreserved ports:

----
setsebool -P pcp_bind_all_unreserved_ports on
----

Let's restart pcp:

----
systemctl restart pmcd pmlogger
----

Now back on node2, let's set up remote logging for node3:

Edit /etc/pcp/pmlogger/control.d/remote and add:
----
192.168.1.4 n n PCP_LOG_DIR/pmlogger/node3 -r T24h10m -c config.remote
----

replacing `192.168.1.4` with the actual IP address of node3.

Now, let's restart pcp:

----
systemctl restart pmcd pmlogger
----

Let's verify that we are now getting logs from node3:

----
cd /var/log/pcp/pmlogger/node3
for i in $(ls *.0); do pmdumplog -L $i; done
----

This should generate output similar to:

----
Log Label (Log Format Version 2)
Performance metrics from host node3
    commencing Thu Aug 13 21:39:06.614021 2020
    ending     Thu Aug 13 21:39:07.322042 2020
Archive timezone: CEST-2
PID for pmlogger: 5595
Log Label (Log Format Version 2)
Performance metrics from host node3
    commencing Thu Aug 13 21:39:15.271834 2020
    ending     Thu Aug 13 21:39:15.307463 2020
Archive timezone: CEST-2
PID for pmlogger: 6842
----

If you something like the above, then you have successfully set up remote logging. node2 is now accepting remote logs from node3 and further, metrics for node3 and node2 are being stored in the pmseries redis database!

== Grafana Integration

== Additional Resources

NOTE: You are not required to reference any additional resources for these exercises.  This is informational only.

    * link:http://www.brendangregg.com/ebpf.html[Linux Extended BPF (eBPF Tracing Tools) - Brendan Gregg]
    * link:https://github.com/xdp-project/xdp-tutorial[Upstream XDP Tutorial (eXpress Data Path networking is tech preview in RHEL 8.2.)]
    * link:https://developers.redhat.com/blog/tag/ebpf/[eBPF blogs on Red Hat Developer (covering the networking aspect)]

[discrete]
== End of Unit

ifdef::env-github[]
link:../RHEL8-Workshop.adoc#toc[Return to TOC]
endif::[]

////
Alway end files with a blank line to avoid include problems.
////
